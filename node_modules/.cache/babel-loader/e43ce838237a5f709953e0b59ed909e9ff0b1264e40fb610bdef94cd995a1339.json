{"ast":null,"code":"import \"core-js/modules/es.array.push.js\";\nimport \"core-js/modules/es.iterator.constructor.js\";\nimport \"core-js/modules/es.iterator.filter.js\";\nimport \"core-js/modules/es.iterator.find.js\";\nimport \"core-js/modules/es.iterator.map.js\";\nimport \"core-js/modules/web.url-search-params.delete.js\";\nimport \"core-js/modules/web.url-search-params.has.js\";\nimport \"core-js/modules/web.url-search-params.size.js\";\nimport ModelSelector from './ModelSelector.vue';\nimport RoleList from './RoleBox/RoleList.vue';\nimport TabSelector from './TabSelector.vue';\nimport Message from './ChatBox/MessageBox.vue';\nimport InputBox from './ChatBox/InputBox.vue';\nimport Glm4V from './ImgBox/Glm4V.vue';\nimport CogView from './ImgBox/CogView.vue';\nimport VideoGlm from './ImgBox/VideoGlm.vue';\nimport VideoImg from './ImgBox/VideoImg.vue';\nimport FooterBox from './FooterBox.vue';\nimport { fetchAIResponse, API_CONFIG } from '../utils/api';\nimport { ChatPrompts } from '../utils/prompt.js';\nexport default {\n  components: {\n    ModelSelector,\n    TabSelector,\n    RoleList,\n    Message,\n    InputBox,\n    FooterBox,\n    Glm4V,\n    CogView,\n    VideoGlm,\n    VideoImg\n  },\n  data() {\n    return {\n      messages: [],\n      // 初始化为空\n      isThinking: false,\n      mode: 'angry',\n      model: 'gpt35',\n      tab: 'chat',\n      isDeepThinking: false,\n      abortController: null // 用来保存 AbortController 实例\n    };\n  },\n  methods: {\n    async sendMessage(userInput) {\n      if (userInput.trim() === '') return;\n\n      // 插入用户消息\n      this.messages.push({\n        role: 'user',\n        content: userInput,\n        id: Date.now()\n      });\n      const loadingMessage = {\n        role: 'assistant',\n        content: '思考中',\n        id: 'loading-' + Date.now()\n      };\n      this.messages.push(loadingMessage);\n      this.isThinking = true;\n\n      // 创建新的 AbortController 实例\n      this.abortController = new AbortController();\n\n      // 获取 AI 响应，传入 abortController\n      await this.getAIResponse(loadingMessage.id, this.abortController);\n      this.isThinking = false;\n      this.scrollToBottom();\n    },\n    async getAIResponse(loadingMessageId, controller) {\n      try {\n        const systemMessage = this.getSystemMessage();\n        const messages = [{\n          role: 'system',\n          content: systemMessage\n        }, ...this.messages.filter(msg => msg.id !== loadingMessageId).map(msg => ({\n          role: msg.role,\n          content: msg.content\n        }))];\n        const {\n          apiUrl,\n          apiKey,\n          modelName,\n          temperature\n        } = this.getApiConfig();\n        let reasoningContent = '';\n        let finalContent = '';\n        let totalTokens = 0;\n        const index = this.messages.findIndex(msg => msg.id === loadingMessageId);\n        if (index !== -1) {\n          this.messages = [...this.messages.slice(0, index), {\n            role: 'assistant',\n            content: '思考中',\n            reasoningContent: '',\n            token: 0,\n            duration: 0,\n            id: this.generateUniqueId(),\n            mode: this.mode,\n            model: this.model\n          }, ...this.messages.slice(index + 1)];\n        }\n        const stream = true;\n        await fetchAIResponse(apiUrl, apiKey, modelName, messages, temperature, stream, chunk => {\n          if (controller.signal.aborted) {\n            return; // 请求被中止，退出\n          }\n          if (chunk.type === 'reasoning') {\n            reasoningContent += chunk.content;\n            totalTokens = parseFloat((totalTokens + chunk.token).toFixed(4));\n\n            // 获取当前消息对象\n            const currentMessage = this.messages[index];\n\n            // 如果是第一次进入 reasoning 阶段，记录开始时间\n            if (!currentMessage.reasoningStartTime) {\n              currentMessage.reasoningStartTime = Date.now();\n            }\n\n            // 计算深度思考持续时间\n            const currentTime = Date.now();\n            currentMessage.reasoningDuration = parseFloat(((currentTime - currentMessage.reasoningStartTime) / 1000).toFixed(1));\n            this.messages = [...this.messages.slice(0, index), {\n              ...currentMessage,\n              reasoningContent,\n              token: totalTokens,\n              duration: chunk.duration\n            },\n            // 更新消息对象\n            ...this.messages.slice(index + 1)];\n          } else if (chunk.type === 'content') {\n            finalContent += chunk.content;\n            totalTokens = parseFloat((totalTokens + chunk.token).toFixed(4));\n            this.messages = [...this.messages.slice(0, index), {\n              ...this.messages[index],\n              content: finalContent,\n              token: totalTokens,\n              duration: chunk.duration\n            }, ...this.messages.slice(index + 1)];\n          } else if (chunk.type === 'complete') {\n            this.messages = [...this.messages.slice(0, index), {\n              ...this.messages[index],\n              duration: chunk.duration\n            }, ...this.messages.slice(index + 1)];\n          }\n          this.conditionalScrollToBottom();\n        }, controller);\n      } catch (error) {\n        if (error.name !== 'AbortError') {\n          this.messages = [{\n            role: 'assistant',\n            content: '这个模型出现了问题，请换个模型试试！',\n            id: this.generateUniqueId()\n          }];\n        }\n      }\n    },\n    conditionalScrollToBottom() {\n      const chatContainer = this.$refs.chatContainer;\n      if (!chatContainer) return; // Ensure container exists\n\n      const isAtBottom = chatContainer.scrollHeight - chatContainer.scrollTop <= chatContainer.clientHeight + 50; // Add a tolerance of 50px\n\n      if (isAtBottom) {\n        this.scrollToBottom();\n      }\n    },\n    scrollToBottom() {\n      this.$nextTick(() => {\n        const chatContainer = this.$refs.chatContainer;\n        chatContainer.scrollTop = chatContainer.scrollHeight;\n      });\n    },\n    generateUniqueId() {\n      return Date.now().toString(36) + Math.random().toString(36).substring(2);\n    },\n    getSystemMessage() {\n      // if (this.isDeepThinking) {\n      //     return '' // 深度思考模式下，systemMessage 为空\n      // }\n      const prompt = ChatPrompts.find(p => p.mode === this.mode);\n      return prompt ? prompt.systemMessage : '你是一个正常的助手，请用礼貌的语言回答问题。';\n    },\n    getApiConfig() {\n      // 直接从配置文件中获取当前模型的配置\n      const config = API_CONFIG[this.model];\n      if (!config) {\n        throw new Error(`未找到模型 ${this.model} 的配置`);\n      }\n      return config;\n    },\n    changeMode(newMode) {\n      // 如果有正在进行的请求，取消它\n      if (this.abortController) {\n        this.abortController.abort();\n      }\n      this.mode = newMode;\n      this.messages = []; // 清空消息列表\n      if (!this.isDeepThinking) {\n        this.insertDefaultMessage(); // 如果不是深度思考模式，插入默认的第一个对话\n      }\n      this.isThinking = false;\n    },\n    changeModel(newModel) {\n      // 如果有正在进行的请求，取消它\n      if (this.abortController) {\n        this.abortController.abort();\n      }\n      this.model = newModel;\n      if (newModel === 'shuinifengxin') {\n        this.mode = 'rude';\n      } else {\n        this.mode = 'normal';\n      }\n      this.messages = []; // 清空消息列表\n\n      if (!this.isDeepThinking) {\n        this.insertDefaultMessage(); // 插入默认对话\n      }\n      this.isThinking = false;\n      this.$refs.inputBox.init();\n    },\n    insertDefaultMessage() {\n      let messageContent = '你好！请问有什么可以帮您的？';\n      this.messages.push({\n        role: 'assistant',\n        content: messageContent,\n        model: this.model\n      });\n    },\n    changeTab(newTab) {\n      this.tab = newTab;\n      this.isDeepThinking = false;\n      this.model = 'gpt35';\n      this.messages = [];\n      this.insertDefaultMessage();\n    },\n    // 切换深度思考\n    toggleDeepThinking(isDeepThinking) {\n      this.isDeepThinking = isDeepThinking;\n      if (isDeepThinking) {\n        // 深度思考模式下，清空消息列表\n        // this.messages = []\n        this.model = 'deepThinking';\n      } else {\n        this.model = 'deepseek';\n        // 非深度思考模式下，插入默认的第一个对话\n        // this.insertDefaultMessage()\n      }\n    }\n  },\n  mounted() {\n    // 获取Url中的参数model 然后赋值给this.model\n    const urlParams = new URLSearchParams(window.location.search);\n    const modelParam = urlParams.get('model');\n    const tabParam = urlParams.get('tab');\n    if (modelParam) {\n      this.model = modelParam;\n    }\n    if (tabParam) {\n      this.tab = tabParam;\n    }\n\n    // 初始化时根据深度思考状态决定是否插入默认消息\n    if (!this.isDeepThinking) {\n      this.insertDefaultMessage();\n    }\n  }\n};","map":{"version":3,"names":["ModelSelector","RoleList","TabSelector","Message","InputBox","Glm4V","CogView","VideoGlm","VideoImg","FooterBox","fetchAIResponse","API_CONFIG","ChatPrompts","components","data","messages","isThinking","mode","model","tab","isDeepThinking","abortController","methods","sendMessage","userInput","trim","push","role","content","id","Date","now","loadingMessage","AbortController","getAIResponse","scrollToBottom","loadingMessageId","controller","systemMessage","getSystemMessage","filter","msg","map","apiUrl","apiKey","modelName","temperature","getApiConfig","reasoningContent","finalContent","totalTokens","index","findIndex","slice","token","duration","generateUniqueId","stream","chunk","signal","aborted","type","parseFloat","toFixed","currentMessage","reasoningStartTime","currentTime","reasoningDuration","conditionalScrollToBottom","error","name","chatContainer","$refs","isAtBottom","scrollHeight","scrollTop","clientHeight","$nextTick","toString","Math","random","substring","prompt","find","p","config","Error","changeMode","newMode","abort","insertDefaultMessage","changeModel","newModel","inputBox","init","messageContent","changeTab","newTab","toggleDeepThinking","mounted","urlParams","URLSearchParams","window","location","search","modelParam","get","tabParam"],"sources":["src/components/ChatBox.vue"],"sourcesContent":["<template>\n    <div class=\"min-h-screen flex flex-col absolute inset-0 -z-10 h-full w-full bg-main\">\n        <div class=\"main min-h-screen flex flex-col absolute inset-0 -z-10 h-full w-full\">\n            <!-- 模型选择 -->\n            <TabSelector :tab=\"tab\" @tab-selected=\"changeTab\" />\n            <template v-if=\"tab === 'chat'\">\n                <ModelSelector v-if=\"!isDeepThinking\" :model=\"model\" @change-model=\"changeModel\" />\n\n                <!-- 聊天记录区域 -->\n                <div ref=\"chatContainer\" class=\"flex-1 p-2 overflow-y-auto pb-2 chatContainer\">\n                    <!-- 消息列表 -->\n                    <Message v-for=\"message in messages\" :key=\"message.id\" :message=\"message\" />\n                </div>\n\n                <!-- 输入框区域 -->\n                <InputBox\n                    ref=\"inputBox\"\n                    :is-thinking=\"isThinking\"\n                    :showMode=\"true\"\n                    :mode=\"mode\"\n                    :model=\"model\"\n                    @send-message=\"sendMessage\"\n                    @scroll-to-bottom=\"scrollToBottom\"\n                    @change-mode=\"changeMode\"\n                    @toggle-deep-thinking=\"toggleDeepThinking\"\n                />\n            </template>\n            <!-- 大模型竞技场 -->\n            <template v-else-if=\"tab === 'battle'\">\n                <iframe\n                    src=\"https://bisheng.dataelem.com/chat/flow/f6e1f49e-7d84-4f83-bd0a-bb8874b7833a\"\n                    style=\"width: 100%; height: 100%; min-height: 700px\"\n                    frameborder=\"0\"\n                    allow=\"fullscreen;clipboard-write\"\n                >\n                </iframe>\n            </template>\n            <!-- 角色对话 -->\n            <template v-else-if=\"tab === 'role'\">\n                <RoleList />\n            </template>\n            <!-- 图片识别大模型-智谱 -->\n            <template v-else-if=\"tab === 'image'\">\n                <Glm4V />\n            </template>\n            <!-- 生图大模型 -->\n            <template v-else-if=\"tab === 'cogview'\">\n                <CogView />\n            </template>\n            <!-- 视频生成大模型 -->\n            <template v-else-if=\"tab === 'textvideo'\">\n                <VideoGlm />\n            </template>\n            <template v-else-if=\"tab === 'imgvideo'\">\n                <VideoImg />\n            </template>\n            <FooterBox />\n        </div>\n    </div>\n</template>\n\n<script>\nimport ModelSelector from './ModelSelector.vue'\nimport RoleList from './RoleBox/RoleList.vue'\nimport TabSelector from './TabSelector.vue'\nimport Message from './ChatBox/MessageBox.vue'\nimport InputBox from './ChatBox/InputBox.vue'\nimport Glm4V from './ImgBox/Glm4V.vue'\nimport CogView from './ImgBox/CogView.vue'\nimport VideoGlm from './ImgBox/VideoGlm.vue'\nimport VideoImg from './ImgBox/VideoImg.vue'\nimport FooterBox from './FooterBox.vue'\nimport { fetchAIResponse, API_CONFIG } from '../utils/api'\nimport { ChatPrompts } from '../utils/prompt.js'\nexport default {\n    components: {\n        ModelSelector,\n        TabSelector,\n        RoleList,\n        Message,\n        InputBox,\n        FooterBox,\n        Glm4V,\n        CogView,\n        VideoGlm,\n        VideoImg\n    },\n    data() {\n        return {\n            messages: [], // 初始化为空\n            isThinking: false,\n            mode: 'angry',\n            model: 'gpt35',\n            tab: 'chat',\n            isDeepThinking: false,\n            abortController: null // 用来保存 AbortController 实例\n        }\n    },\n    methods: {\n        async sendMessage(userInput) {\n            if (userInput.trim() === '') return\n\n            // 插入用户消息\n            this.messages.push({\n                role: 'user',\n                content: userInput,\n                id: Date.now()\n            })\n\n            const loadingMessage = {\n                role: 'assistant',\n                content: '思考中',\n                id: 'loading-' + Date.now()\n            }\n            this.messages.push(loadingMessage)\n\n            this.isThinking = true\n\n            // 创建新的 AbortController 实例\n            this.abortController = new AbortController()\n\n            // 获取 AI 响应，传入 abortController\n            await this.getAIResponse(loadingMessage.id, this.abortController)\n\n            this.isThinking = false\n            this.scrollToBottom()\n        },\n        async getAIResponse(loadingMessageId, controller) {\n            try {\n                const systemMessage = this.getSystemMessage()\n                const messages = [\n                    { role: 'system', content: systemMessage },\n                    ...this.messages.filter(msg => msg.id !== loadingMessageId).map(msg => ({ role: msg.role, content: msg.content }))\n                ]\n\n                const { apiUrl, apiKey, modelName, temperature } = this.getApiConfig()\n\n                let reasoningContent = ''\n                let finalContent = ''\n                let totalTokens = 0\n\n                const index = this.messages.findIndex(msg => msg.id === loadingMessageId)\n                if (index !== -1) {\n                    this.messages = [\n                        ...this.messages.slice(0, index),\n                        {\n                            role: 'assistant',\n                            content: '思考中',\n                            reasoningContent: '',\n                            token: 0,\n                            duration: 0,\n                            id: this.generateUniqueId(),\n                            mode: this.mode,\n                            model: this.model\n                        },\n                        ...this.messages.slice(index + 1)\n                    ]\n                }\n\n                const stream = true\n                await fetchAIResponse(\n                    apiUrl,\n                    apiKey,\n                    modelName,\n                    messages,\n                    temperature,\n                    stream,\n                    chunk => {\n                        if (controller.signal.aborted) {\n                            return // 请求被中止，退出\n                        }\n\n                        if (chunk.type === 'reasoning') {\n                            reasoningContent += chunk.content\n                            totalTokens = parseFloat((totalTokens + chunk.token).toFixed(4))\n\n                            // 获取当前消息对象\n                            const currentMessage = this.messages[index]\n\n                            // 如果是第一次进入 reasoning 阶段，记录开始时间\n                            if (!currentMessage.reasoningStartTime) {\n                                currentMessage.reasoningStartTime = Date.now()\n                            }\n\n                            // 计算深度思考持续时间\n                            const currentTime = Date.now()\n                            currentMessage.reasoningDuration = parseFloat(((currentTime - currentMessage.reasoningStartTime) / 1000).toFixed(1))\n\n                            this.messages = [\n                                ...this.messages.slice(0, index),\n                                { ...currentMessage, reasoningContent, token: totalTokens, duration: chunk.duration }, // 更新消息对象\n                                ...this.messages.slice(index + 1)\n                            ]\n                        } else if (chunk.type === 'content') {\n                            finalContent += chunk.content\n                            totalTokens = parseFloat((totalTokens + chunk.token).toFixed(4))\n                            this.messages = [\n                                ...this.messages.slice(0, index),\n                                { ...this.messages[index], content: finalContent, token: totalTokens, duration: chunk.duration },\n                                ...this.messages.slice(index + 1)\n                            ]\n                        } else if (chunk.type === 'complete') {\n                            this.messages = [...this.messages.slice(0, index), { ...this.messages[index], duration: chunk.duration }, ...this.messages.slice(index + 1)]\n                        }\n                        this.conditionalScrollToBottom()\n                    },\n                    controller\n                )\n            } catch (error) {\n                if (error.name !== 'AbortError') {\n                    this.messages = [{ role: 'assistant', content: '这个模型出现了问题，请换个模型试试！', id: this.generateUniqueId() }]\n                }\n            }\n        },\n        conditionalScrollToBottom() {\n            const chatContainer = this.$refs.chatContainer\n            if (!chatContainer) return // Ensure container exists\n\n            const isAtBottom = chatContainer.scrollHeight - chatContainer.scrollTop <= chatContainer.clientHeight + 50 // Add a tolerance of 50px\n\n            if (isAtBottom) {\n                this.scrollToBottom()\n            }\n        },\n        scrollToBottom() {\n            this.$nextTick(() => {\n                const chatContainer = this.$refs.chatContainer\n                chatContainer.scrollTop = chatContainer.scrollHeight\n            })\n        },\n        generateUniqueId() {\n            return Date.now().toString(36) + Math.random().toString(36).substring(2)\n        },\n        getSystemMessage() {\n            // if (this.isDeepThinking) {\n            //     return '' // 深度思考模式下，systemMessage 为空\n            // }\n            const prompt = ChatPrompts.find(p => p.mode === this.mode)\n            return prompt ? prompt.systemMessage : '你是一个正常的助手，请用礼貌的语言回答问题。'\n        },\n        getApiConfig() {\n            // 直接从配置文件中获取当前模型的配置\n            const config = API_CONFIG[this.model]\n            if (!config) {\n                throw new Error(`未找到模型 ${this.model} 的配置`)\n            }\n            return config\n        },\n        changeMode(newMode) {\n            // 如果有正在进行的请求，取消它\n            if (this.abortController) {\n                this.abortController.abort()\n            }\n            this.mode = newMode\n            this.messages = [] // 清空消息列表\n            if (!this.isDeepThinking) {\n                this.insertDefaultMessage() // 如果不是深度思考模式，插入默认的第一个对话\n            }\n            this.isThinking = false\n        },\n        changeModel(newModel) {\n            // 如果有正在进行的请求，取消它\n            if (this.abortController) {\n                this.abortController.abort()\n            }\n\n            this.model = newModel\n            if (newModel === 'shuinifengxin') {\n                this.mode = 'rude'\n            } else {\n                this.mode = 'normal'\n            }\n            this.messages = [] // 清空消息列表\n\n            if (!this.isDeepThinking) {\n                this.insertDefaultMessage() // 插入默认对话\n            }\n            this.isThinking = false\n            this.$refs.inputBox.init()\n        },\n        insertDefaultMessage() {\n            let messageContent = '你好！请问有什么可以帮您的？'\n\n            this.messages.push({\n                role: 'assistant',\n                content: messageContent,\n                model: this.model\n            })\n        },\n        changeTab(newTab) {\n            this.tab = newTab\n            this.isDeepThinking = false\n            this.model = 'gpt35'\n            this.messages = []\n            this.insertDefaultMessage()\n        },\n        // 切换深度思考\n        toggleDeepThinking(isDeepThinking) {\n            this.isDeepThinking = isDeepThinking\n            if (isDeepThinking) {\n                // 深度思考模式下，清空消息列表\n                // this.messages = []\n                this.model = 'deepThinking'\n            } else {\n                this.model = 'deepseek'\n                // 非深度思考模式下，插入默认的第一个对话\n                // this.insertDefaultMessage()\n            }\n        }\n    },\n    mounted() {\n        // 获取Url中的参数model 然后赋值给this.model\n        const urlParams = new URLSearchParams(window.location.search)\n        const modelParam = urlParams.get('model')\n        const tabParam = urlParams.get('tab')\n        if (modelParam) {\n            this.model = modelParam\n        }\n        if (tabParam) {\n            this.tab = tabParam\n        }\n\n        // 初始化时根据深度思考状态决定是否插入默认消息\n        if (!this.isDeepThinking) {\n            this.insertDefaultMessage()\n        }\n    }\n}\n</script>\n"],"mappings":";;;;;;;;AA8DA,OAAAA,aAAA;AACA,OAAAC,QAAA;AACA,OAAAC,WAAA;AACA,OAAAC,OAAA;AACA,OAAAC,QAAA;AACA,OAAAC,KAAA;AACA,OAAAC,OAAA;AACA,OAAAC,QAAA;AACA,OAAAC,QAAA;AACA,OAAAC,SAAA;AACA,SAAAC,eAAA,EAAAC,UAAA;AACA,SAAAC,WAAA;AACA;EACAC,UAAA;IACAb,aAAA;IACAE,WAAA;IACAD,QAAA;IACAE,OAAA;IACAC,QAAA;IACAK,SAAA;IACAJ,KAAA;IACAC,OAAA;IACAC,QAAA;IACAC;EACA;EACAM,KAAA;IACA;MACAC,QAAA;MAAA;MACAC,UAAA;MACAC,IAAA;MACAC,KAAA;MACAC,GAAA;MACAC,cAAA;MACAC,eAAA;IACA;EACA;EACAC,OAAA;IACA,MAAAC,YAAAC,SAAA;MACA,IAAAA,SAAA,CAAAC,IAAA;;MAEA;MACA,KAAAV,QAAA,CAAAW,IAAA;QACAC,IAAA;QACAC,OAAA,EAAAJ,SAAA;QACAK,EAAA,EAAAC,IAAA,CAAAC,GAAA;MACA;MAEA,MAAAC,cAAA;QACAL,IAAA;QACAC,OAAA;QACAC,EAAA,eAAAC,IAAA,CAAAC,GAAA;MACA;MACA,KAAAhB,QAAA,CAAAW,IAAA,CAAAM,cAAA;MAEA,KAAAhB,UAAA;;MAEA;MACA,KAAAK,eAAA,OAAAY,eAAA;;MAEA;MACA,WAAAC,aAAA,CAAAF,cAAA,CAAAH,EAAA,OAAAR,eAAA;MAEA,KAAAL,UAAA;MACA,KAAAmB,cAAA;IACA;IACA,MAAAD,cAAAE,gBAAA,EAAAC,UAAA;MACA;QACA,MAAAC,aAAA,QAAAC,gBAAA;QACA,MAAAxB,QAAA,IACA;UAAAY,IAAA;UAAAC,OAAA,EAAAU;QAAA,GACA,QAAAvB,QAAA,CAAAyB,MAAA,CAAAC,GAAA,IAAAA,GAAA,CAAAZ,EAAA,KAAAO,gBAAA,EAAAM,GAAA,CAAAD,GAAA;UAAAd,IAAA,EAAAc,GAAA,CAAAd,IAAA;UAAAC,OAAA,EAAAa,GAAA,CAAAb;QAAA,IACA;QAEA;UAAAe,MAAA;UAAAC,MAAA;UAAAC,SAAA;UAAAC;QAAA,SAAAC,YAAA;QAEA,IAAAC,gBAAA;QACA,IAAAC,YAAA;QACA,IAAAC,WAAA;QAEA,MAAAC,KAAA,QAAApC,QAAA,CAAAqC,SAAA,CAAAX,GAAA,IAAAA,GAAA,CAAAZ,EAAA,KAAAO,gBAAA;QACA,IAAAe,KAAA;UACA,KAAApC,QAAA,IACA,QAAAA,QAAA,CAAAsC,KAAA,IAAAF,KAAA,GACA;YACAxB,IAAA;YACAC,OAAA;YACAoB,gBAAA;YACAM,KAAA;YACAC,QAAA;YACA1B,EAAA,OAAA2B,gBAAA;YACAvC,IAAA,OAAAA,IAAA;YACAC,KAAA,OAAAA;UACA,GACA,QAAAH,QAAA,CAAAsC,KAAA,CAAAF,KAAA,MACA;QACA;QAEA,MAAAM,MAAA;QACA,MAAA/C,eAAA,CACAiC,MAAA,EACAC,MAAA,EACAC,SAAA,EACA9B,QAAA,EACA+B,WAAA,EACAW,MAAA,EACAC,KAAA;UACA,IAAArB,UAAA,CAAAsB,MAAA,CAAAC,OAAA;YACA;UACA;UAEA,IAAAF,KAAA,CAAAG,IAAA;YACAb,gBAAA,IAAAU,KAAA,CAAA9B,OAAA;YACAsB,WAAA,GAAAY,UAAA,EAAAZ,WAAA,GAAAQ,KAAA,CAAAJ,KAAA,EAAAS,OAAA;;YAEA;YACA,MAAAC,cAAA,QAAAjD,QAAA,CAAAoC,KAAA;;YAEA;YACA,KAAAa,cAAA,CAAAC,kBAAA;cACAD,cAAA,CAAAC,kBAAA,GAAAnC,IAAA,CAAAC,GAAA;YACA;;YAEA;YACA,MAAAmC,WAAA,GAAApC,IAAA,CAAAC,GAAA;YACAiC,cAAA,CAAAG,iBAAA,GAAAL,UAAA,GAAAI,WAAA,GAAAF,cAAA,CAAAC,kBAAA,UAAAF,OAAA;YAEA,KAAAhD,QAAA,IACA,QAAAA,QAAA,CAAAsC,KAAA,IAAAF,KAAA,GACA;cAAA,GAAAa,cAAA;cAAAhB,gBAAA;cAAAM,KAAA,EAAAJ,WAAA;cAAAK,QAAA,EAAAG,KAAA,CAAAH;YAAA;YAAA;YACA,QAAAxC,QAAA,CAAAsC,KAAA,CAAAF,KAAA,MACA;UACA,WAAAO,KAAA,CAAAG,IAAA;YACAZ,YAAA,IAAAS,KAAA,CAAA9B,OAAA;YACAsB,WAAA,GAAAY,UAAA,EAAAZ,WAAA,GAAAQ,KAAA,CAAAJ,KAAA,EAAAS,OAAA;YACA,KAAAhD,QAAA,IACA,QAAAA,QAAA,CAAAsC,KAAA,IAAAF,KAAA,GACA;cAAA,QAAApC,QAAA,CAAAoC,KAAA;cAAAvB,OAAA,EAAAqB,YAAA;cAAAK,KAAA,EAAAJ,WAAA;cAAAK,QAAA,EAAAG,KAAA,CAAAH;YAAA,GACA,QAAAxC,QAAA,CAAAsC,KAAA,CAAAF,KAAA,MACA;UACA,WAAAO,KAAA,CAAAG,IAAA;YACA,KAAA9C,QAAA,YAAAA,QAAA,CAAAsC,KAAA,IAAAF,KAAA;cAAA,QAAApC,QAAA,CAAAoC,KAAA;cAAAI,QAAA,EAAAG,KAAA,CAAAH;YAAA,WAAAxC,QAAA,CAAAsC,KAAA,CAAAF,KAAA;UACA;UACA,KAAAiB,yBAAA;QACA,GACA/B,UACA;MACA,SAAAgC,KAAA;QACA,IAAAA,KAAA,CAAAC,IAAA;UACA,KAAAvD,QAAA;YAAAY,IAAA;YAAAC,OAAA;YAAAC,EAAA,OAAA2B,gBAAA;UAAA;QACA;MACA;IACA;IACAY,0BAAA;MACA,MAAAG,aAAA,QAAAC,KAAA,CAAAD,aAAA;MACA,KAAAA,aAAA;;MAEA,MAAAE,UAAA,GAAAF,aAAA,CAAAG,YAAA,GAAAH,aAAA,CAAAI,SAAA,IAAAJ,aAAA,CAAAK,YAAA;;MAEA,IAAAH,UAAA;QACA,KAAAtC,cAAA;MACA;IACA;IACAA,eAAA;MACA,KAAA0C,SAAA;QACA,MAAAN,aAAA,QAAAC,KAAA,CAAAD,aAAA;QACAA,aAAA,CAAAI,SAAA,GAAAJ,aAAA,CAAAG,YAAA;MACA;IACA;IACAlB,iBAAA;MACA,OAAA1B,IAAA,CAAAC,GAAA,GAAA+C,QAAA,OAAAC,IAAA,CAAAC,MAAA,GAAAF,QAAA,KAAAG,SAAA;IACA;IACA1C,iBAAA;MACA;MACA;MACA;MACA,MAAA2C,MAAA,GAAAtE,WAAA,CAAAuE,IAAA,CAAAC,CAAA,IAAAA,CAAA,CAAAnE,IAAA,UAAAA,IAAA;MACA,OAAAiE,MAAA,GAAAA,MAAA,CAAA5C,aAAA;IACA;IACAS,aAAA;MACA;MACA,MAAAsC,MAAA,GAAA1E,UAAA,MAAAO,KAAA;MACA,KAAAmE,MAAA;QACA,UAAAC,KAAA,eAAApE,KAAA;MACA;MACA,OAAAmE,MAAA;IACA;IACAE,WAAAC,OAAA;MACA;MACA,SAAAnE,eAAA;QACA,KAAAA,eAAA,CAAAoE,KAAA;MACA;MACA,KAAAxE,IAAA,GAAAuE,OAAA;MACA,KAAAzE,QAAA;MACA,UAAAK,cAAA;QACA,KAAAsE,oBAAA;MACA;MACA,KAAA1E,UAAA;IACA;IACA2E,YAAAC,QAAA;MACA;MACA,SAAAvE,eAAA;QACA,KAAAA,eAAA,CAAAoE,KAAA;MACA;MAEA,KAAAvE,KAAA,GAAA0E,QAAA;MACA,IAAAA,QAAA;QACA,KAAA3E,IAAA;MACA;QACA,KAAAA,IAAA;MACA;MACA,KAAAF,QAAA;;MAEA,UAAAK,cAAA;QACA,KAAAsE,oBAAA;MACA;MACA,KAAA1E,UAAA;MACA,KAAAwD,KAAA,CAAAqB,QAAA,CAAAC,IAAA;IACA;IACAJ,qBAAA;MACA,IAAAK,cAAA;MAEA,KAAAhF,QAAA,CAAAW,IAAA;QACAC,IAAA;QACAC,OAAA,EAAAmE,cAAA;QACA7E,KAAA,OAAAA;MACA;IACA;IACA8E,UAAAC,MAAA;MACA,KAAA9E,GAAA,GAAA8E,MAAA;MACA,KAAA7E,cAAA;MACA,KAAAF,KAAA;MACA,KAAAH,QAAA;MACA,KAAA2E,oBAAA;IACA;IACA;IACAQ,mBAAA9E,cAAA;MACA,KAAAA,cAAA,GAAAA,cAAA;MACA,IAAAA,cAAA;QACA;QACA;QACA,KAAAF,KAAA;MACA;QACA,KAAAA,KAAA;QACA;QACA;MACA;IACA;EACA;EACAiF,QAAA;IACA;IACA,MAAAC,SAAA,OAAAC,eAAA,CAAAC,MAAA,CAAAC,QAAA,CAAAC,MAAA;IACA,MAAAC,UAAA,GAAAL,SAAA,CAAAM,GAAA;IACA,MAAAC,QAAA,GAAAP,SAAA,CAAAM,GAAA;IACA,IAAAD,UAAA;MACA,KAAAvF,KAAA,GAAAuF,UAAA;IACA;IACA,IAAAE,QAAA;MACA,KAAAxF,GAAA,GAAAwF,QAAA;IACA;;IAEA;IACA,UAAAvF,cAAA;MACA,KAAAsE,oBAAA;IACA;EACA;AACA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}